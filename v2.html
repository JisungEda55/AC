<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>Whisper WASM ìë§‰ ìƒì„±ê¸° (ì„œë²„ ì—†ìŒ/í‚¤ ì—†ìŒ)</title>
    <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.12.10/dist/umd/ffmpeg.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/util@0.12.1/dist/umd/index.min.js"></script>
    <style>
        body { font-family: sans-serif; padding: 20px; background: #f0f2f5; }
        .card { background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); max-width: 700px; margin: auto; }
        #status { color: #007bff; font-weight: bold; margin: 10px 0; }
        pre { background: #333; color: #fff; padding: 15px; border-radius: 5px; height: 200px; overflow-y: auto; font-size: 12px; }
        button { padding: 10px 20px; cursor: pointer; border: none; border-radius: 5px; background: #28a745; color: white; }
        button:disabled { background: #ccc; }
    </style>
</head>
<body>

<div class="card">
    <h2>ğŸ¥ ë¸Œë¼ìš°ì € ë‹¨ë… ìë§‰ ìƒì„±ê¸°</h2>
    <p>ì„œë²„ í†µì‹  ì—†ì´ ë¸Œë¼ìš°ì € ì•ˆì—ì„œ AIê°€ ì‘ë™í•©ë‹ˆë‹¤.</p>
    
    <input type="file" id="videoInput" accept="video/*">
    <div id="status">íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.</div>
    
    <button id="startBtn">ìë§‰ ìƒì„± ì‹œì‘</button>
    <button id="downloadBtn" disabled>SRT ë‹¤ìš´ë¡œë“œ</button>

    <h3>ë¯¸ë¦¬ë³´ê¸°</h3>
    <pre id="output">ìë§‰ì´ ìƒì„±ë˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</pre>
</div>

<script type="module">
    const { FFmpeg } = FFmpegWASM;
    const { fetchFile, toBlobURL } = FFmpegUtil;
    const ffmpeg = new FFmpeg();

    const startBtn = document.getElementById('startBtn');
    const downloadBtn = document.getElementById('downloadBtn');
    const status = document.getElementById('status');
    const output = document.getElementById('output');

    let finalSrt = "";

    startBtn.onclick = async () => {
        const file = document.getElementById('videoInput').files[0];
        if (!file) return alert("ë™ì˜ìƒì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”.");

        try {
            startBtn.disabled = true;
            
            // 1. FFmpeg ë¡œë“œ (WASM íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°)
            if (!ffmpeg.loaded) {
                status.innerText = "â³ FFmpeg ë¡œë”© ì¤‘...";
                await ffmpeg.load({
                    coreURL: await toBlobURL('https://cdn.jsdelivr.net/npm/@ffmpeg/core@0.12.6/dist/umd/ffmpeg-core.js', 'text/javascript'),
                    wasmURL: await toBlobURL('https://cdn.jsdelivr.net/npm/@ffmpeg/core@0.12.6/dist/umd/ffmpeg-core.wasm', 'application/wasm'),
                });
            }

            // 2. ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (WASM ë‚´ë¶€ íŒŒì¼ ì‹œìŠ¤í…œ ì´ìš©)
            status.innerText = "ğŸ”Š ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...";
            await ffmpeg.writeFile('input', await fetchFile(file));
            await ffmpeg.exec(['-i', 'input', '-ar', '16000', '-ac', '1', 'output.wav']);
            const audioData = await ffmpeg.readFile('output.wav');
            const audioBlob = new Blob([audioData.buffer], { type: 'audio/wav' });

            // 3. Whisper AI ì‹¤í–‰ (Worker í˜¸ì¶œ)
            status.innerText = "ğŸ¤– AI ìŒì„± ì¸ì‹ ì‹œì‘ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ 1~2ë¶„ ì†Œìš”)...";
            transcribe(audioBlob);

        } catch (e) {
            console.error(e);
            status.innerText = "âŒ ì˜¤ë¥˜ ë°œìƒ: " + e.message;
            startBtn.disabled = false;
        }
    };

    function transcribe(blob) {
        // ë³„ë„ ì›Œì»¤ ìƒì„± (UI ë©ˆì¶¤ ë°©ì§€)
        const workerCode = `
            import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

            self.onmessage = async (e) => {
                try {
                    const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny');
                    const url = URL.createObjectURL(e.data.blob);
                    
                    const result = await transcriber(url, { 
                        chunk_length_s: 30, 
                        stride_length_s: 5,
                        language: 'korean',
                        return_timestamps: true 
                    });

                    self.postMessage({ status: 'complete', result });
                } catch (err) {
                    self.postMessage({ status: 'error', error: err.message });
                }
            };
        `;

        const worker = new Worker(URL.createObjectURL(new Blob([workerCode], { type: 'application/javascript' })), { type: 'module' });
        worker.postMessage({ blob });

        worker.onmessage = (e) => {
            if (e.data.status === 'complete') {
                finalSrt = makeSRT(e.data.result.chunks);
                output.innerText = finalSrt;
                status.innerText = "âœ… ì™„ë£Œ!";
                downloadBtn.disabled = false;
            } else {
                status.innerText = "âŒ ì¸ì‹ ì˜¤ë¥˜: " + e.data.error;
            }
            startBtn.disabled = false;
        };
    }

    function makeSRT(chunks) {
        return chunks.map((c, i) => {
            const start = formatTime(c.timestamp[0]);
            const end = formatTime(c.timestamp[1] || c.timestamp[0] + 2);
            return \`\${i + 1}\\n\${start} --> \${end}\\n\${c.text.trim()}\\n\\n\`;
        }).join('');
    }

    function formatTime(s) {
        const ms = Math.floor((s % 1) * 1000).toString().padStart(3, '0');
        const hms = new Date(s * 1000).toISOString().substr(11, 8);
        return \`\${hms},\${ms}\`;
    }

    downloadBtn.onclick = () => {
        const blob = new Blob([finalSrt], { type: 'text/plain' });
        const a = document.createElement('a');
        a.href = URL.createObjectURL(blob);
        a.download = "subtitles.srt";
        a.click();
    };
</script>

</body>
</html>
